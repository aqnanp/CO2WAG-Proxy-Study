{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library\n",
    "\n",
    "Load all the needed library. <br>\n",
    "<u>Needed library</u> : numpy, matplotlib, pandas, tensorflow, skopt, keras, sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import statistics\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Input\n",
    "from tensorflow.keras.layers import Reshape, MaxPooling2D\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import skopt\n",
    "from skopt import gp_minimize, forest_minimize\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.plots import plot_convergence\n",
    "from skopt.plots import plot_objective, plot_evaluations\n",
    "from skopt.plots import plot_histogram, plot_objective_2D\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function\n",
    "\n",
    "In this study, parameter below are studied:\n",
    "\n",
    "| Parameter | Value | Notes |\n",
    "|:---------|:------------:|:--------------|\n",
    "| Learning rate | 10$^{-6}$-10$^{-2}$ | Learning rate of the optimizer function |\n",
    "| Number of layers | 1 - 3 | Number of hidden layer | \n",
    "| Number of neurons | 2 - 20 | Number of nodes in each hidden layer | \n",
    "| Activation function | Relu | Activation function on each nodes | \n",
    "| Optimizer | Adam | Function to optimize the NN | \n",
    "| Batch size | 64 | Data points that pass through NN every step | \n",
    "| Dropout | - | Proobability where nodes are randomly disconected during training | \n",
    "| Epoch | 100 | Amount of times to go through our training data |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "def ANN_model(features, target, learn_rate, layers, nodes):\n",
    "    \"\"\"\n",
    "    Input Data:\n",
    "    features   : Input data for the ANN (numpy array)\n",
    "    target     : Output of the ANN (numpy array)\n",
    "    learn_rate : Learning-rate for the optimizer.\n",
    "    layers     : Number of dense layers.\n",
    "    nodes      : Number of nodes in each dense layer.\n",
    "    \"\"\"\n",
    "        \n",
    "    # Define model\n",
    "    model = Sequential()\n",
    "    if layers == 1:\n",
    "        # Input layer\n",
    "        model.add(Dense(nodes, activation='relu', \n",
    "                       input_dim=features.shape[1]))      \n",
    "    else:\n",
    "        model.add(Dense(nodes, activation='relu', \n",
    "                       input_dim=features.shape[1]))\n",
    "        for i in range(layers-1):\n",
    "            model.add(Dense(nodes, activation='relu'))\n",
    "\n",
    "    # Add output layer, 1 nodes\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    adam = Adam(lr=learn_rate)\n",
    "    model.compile(optimizer=adam, loss='mse',\n",
    "                  metrics=['mean_absolute_percentage_error',\n",
    "                           'RootMeanSquaredError'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-Parameter Tuning\n",
    "# Parameter to be studied : Learning Rate, Num of Layers, Neurons, Activation Function\n",
    "dim_learn_rate = Real(low=1e-6, high=1e-2, prior='log-uniform',\n",
    "                         name='learn_rate')\n",
    "dim_layers = Integer(low=1, high=3, name='layers')\n",
    "dim_nodes = Integer(low=2, high=5, name='nodes')\n",
    "                             \n",
    "dimensions = [dim_learn_rate, dim_layers, dim_nodes]\n",
    "\n",
    "# Function\n",
    "@use_named_args(dimensions=dimensions)\n",
    "def ANN_study(learn_rate, layers, nodes):\n",
    "    \"\"\"\n",
    "    Hyper-parameters:\n",
    "    features    : Input of the ANN (np.array)\n",
    "    target      : Output of the ANN (np.array)\n",
    "    val_features: Input of the ANN for validation (np.array)\n",
    "    val_target  : Output of the ANN for validation (np.array)\n",
    "    learn_rate  : Learning-rate for the optimizer.\n",
    "    layers      : Number of dense layers.\n",
    "    nodes       : Number of nodes in each dense layer.\n",
    "    activation  : Activation function for all layers.\n",
    "    \"\"\"\n",
    "\n",
    "    # Print the hyper-parameters.\n",
    "    print('Learning rate: {0:.1e}'.format(learn_rate))\n",
    "    print('Dense layers:', layers)\n",
    "    print('Nodes:', nodes)\n",
    "    \n",
    "    model = ANN_model(features=features, \n",
    "                         target=target,\n",
    "                         learn_rate=learn_rate,\n",
    "                         layers=layers,\n",
    "                         nodes=nodes)\n",
    "\n",
    "    # Use Keras to train the model.\n",
    "    patience = 20\n",
    "    es = EarlyStopping(monitor='loss', mode='min', verbose=1, \n",
    "                       patience=patience, restore_best_weights=True)\n",
    "    history = model.fit(features, target, verbose=0, epochs=num_epochs, batch_size = 64,\n",
    "                    validation_data=(val_features, val_target), callbacks=[es])\n",
    "\n",
    "    # Get the regression validation loss\n",
    "    # after the last training-epoch.\n",
    "    if es.stopped_epoch == 0:\n",
    "        loss = history.history['loss'][-1]\n",
    "    else:\n",
    "        loss = history.history['loss'][es.stopped_epoch-patience]\n",
    "\n",
    "    # Print the validation loss.\n",
    "    print()\n",
    "    print('loss:', loss)\n",
    "    print()\n",
    "\n",
    "    # Save the model if it improves on the best-found performance.\n",
    "    # We use the global keyword so we update the variable outside\n",
    "    # of this function.\n",
    "    global best_loss\n",
    "\n",
    "    # If the validation loss of the saved model is improved ...\n",
    "    if loss < best_loss:\n",
    "        # Save the new model to harddisk.\n",
    "        model.save(path_best_model)\n",
    "        \n",
    "        # Update the regression accuracy.\n",
    "        best_loss = loss\n",
    "        \n",
    "        #save the history of the best model\n",
    "        ANN_performance = history.history\n",
    "        temp = json.dumps(ANN_performance)\n",
    "        f = open(path_best_model_performance,\"w\")\n",
    "        f.write(temp)\n",
    "        f.close()\n",
    "\n",
    "    # Delete the Keras model with these hyper-parameters from memory.\n",
    "    del model\n",
    "    \n",
    "    # Clear the Keras session, otherwise it will keep adding new\n",
    "    # models to the same TensorFlow graph each time we create\n",
    "    # a model with a different set of hyper-parameters.\n",
    "    K.clear_session()\n",
    "    \n",
    "    # NOTE: Scikit-optimize does minimization\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Plot\n",
    "Here, functions and plots that used to assess the robustness for each proxy segments is written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for Error and Accuracy of the ANN\n",
    "def plot_error_acc(history):\n",
    "    # history = Fitted ANN model to our dataset\n",
    "\n",
    "    # Loss Function Plot\n",
    "    plt.figure(1)\n",
    "    plt.plot(history['loss'], label='Training Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error [MSE]')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # MAPE Plot\n",
    "    plt.figure(2)\n",
    "    plt.plot(history['mean_absolute_percentage_error'], label='Training')\n",
    "    plt.plot(history['val_mean_absolute_percentage_error'], label='Validation')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MAPE (%)')\n",
    "    plt.ylim([0, 50])\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # RMSE Plot\n",
    "    plt.figure(3)\n",
    "    plt.plot(history['root_mean_squared_error'], label='Training')\n",
    "    plt.plot(history['val_root_mean_squared_error'], label='Validation')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "# Error distribution and proxy performance function for test data\n",
    "def plot_train_performance(model, train_input, train_output, val_input, val_output, lims):\n",
    "    # model = the ANN model (fitted)\n",
    "    # train_input = input for the ANN from training database\n",
    "    # train_output = output of the training database\n",
    "    # val_input = input for the ANN from validation database\n",
    "    # val_output = output of the validation database\n",
    "    # lims = 2 points [min,max] for the plot boundary\n",
    "\n",
    "    # Calculate test data with the model\n",
    "    train_predictions = model.predict(train_input).flatten()\n",
    "    val_predictions = model.predict(val_input).flatten()\n",
    "\n",
    "    # Checking performance of test data\n",
    "    plt.figure(4)\n",
    "    plt.axes(aspect='equal')\n",
    "    plt.scatter(train_output, train_predictions, label='Training')\n",
    "    plt.scatter(val_output, val_predictions, label='Validation', marker='x')\n",
    "    plt.xlabel('True Values')\n",
    "    plt.ylabel('Predictions')\n",
    "    plt.xlim(lims)\n",
    "    plt.ylim(lims)\n",
    "    _ = plt.plot(lims, lims)\n",
    "    \n",
    "    # Getting error distribution\n",
    "    plt.figure(5)\n",
    "    error_train = train_predictions - train_output\n",
    "    error_val = val_predictions - val_output\n",
    "    plt.hist(error_train, bins=25)\n",
    "    plt.hist(error_val, bins=25)\n",
    "    plt.xlabel('Prediction Error [Error]')\n",
    "    _ = plt.ylabel('Count')\n",
    "    \n",
    "    # Calculate R^2\n",
    "    r2_train = r2_score(train_output, train_predictions)\n",
    "    r2_val = r2_score(val_output, val_predictions)\n",
    "    print(\"R-square Training: {:.6f}\".format(r2_train))\n",
    "    print(\"R-square Validation: {:.6f}\".format(r2_val))\n",
    "    \n",
    "    # Calculate Training Absolute Error (AE)\n",
    "    ape_train = abs(train_output-train_predictions)\n",
    "    max_ape_train = max(ape_train)\n",
    "    mean_ape_train = statistics.mean(ape_train)\n",
    "    min_ape_train = min(ape_train)\n",
    "    print(\"\"\"Training Average Absolute Error:\n",
    "    - Maximum=%.6f\n",
    "    - Mean=%.6f\n",
    "    - Minimum=%.6f\"\"\" % (max_ape_train, mean_ape_train, min_ape_train))\n",
    "    \n",
    "    # Calculate Validation Absolute Error (AE)\n",
    "    ape_val = abs(val_output-val_predictions)\n",
    "    max_ape_val = max(ape_val)\n",
    "    mean_ape_val = statistics.mean(ape_val)\n",
    "    min_ape_val = min(ape_val)\n",
    "    print(\"\"\"Validation Average Absolute Error:\n",
    "    - Maximum=%.6f\n",
    "    - Mean=%.6f\n",
    "    - Minimum=%.6f\"\"\" % (max_ape_val, mean_ape_val, min_ape_val))\n",
    "\n",
    "# Error distribution and proxy performance function for test data\n",
    "def plot_test_performance(model, test_input, test_output,lims):\n",
    "    # model = the ANN model (fitted)\n",
    "    # test_input = input for the ANN from test database\n",
    "    # test_output = output of the test database\n",
    "    # lims = 2 points [min,max] for the plot boundary\n",
    "\n",
    "    # Calculate test data with the model\n",
    "    test_predictions = model.predict(test_input).flatten()\n",
    "\n",
    "    # Checking performance of test data\n",
    "    plt.figure(6)\n",
    "    plt.axes(aspect='equal')\n",
    "    plt.scatter(test_output, test_predictions)\n",
    "    plt.xlabel('True Values')\n",
    "    plt.ylabel('Predictions')\n",
    "    plt.xlim(lims)\n",
    "    plt.ylim(lims)\n",
    "    _ = plt.plot(lims, lims)\n",
    "    \n",
    "    # Getting error distribution\n",
    "    plt.figure(7)\n",
    "    error = test_predictions - test_output\n",
    "    plt.hist(error, bins=25)\n",
    "    plt.xlabel('Prediction Error [Error]')\n",
    "    _ = plt.ylabel('Count')\n",
    "    \n",
    "    # Calculate R^2\n",
    "    r2_test = r2_score(test_output, test_predictions)\n",
    "    print(\"R-square Test: {:.6f}\".format(r2_test))\n",
    "    \n",
    "    # Calculate Absolute Error (APE)\n",
    "    ape_test = abs(test_output-test_predictions)\n",
    "    max_ape_test = max(ape_test)\n",
    "    mean_ape_test = statistics.mean(ape_test)\n",
    "    min_ape_test = min(ape_test)\n",
    "    print(\"\"\"Average Absolute Error:\n",
    "    - Maximum=%.6f\n",
    "    - Mean=%.6f\n",
    "    - Minimum=%.6f\"\"\" % (max_ape_test, mean_ape_test, min_ape_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data\n",
    "Upload the data that obtained from Eclipse. Data separated into 75:25 for training and validation. It is randomized with seed=10 for reproducibility. We forced the edge of LHS to be used as training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing database\n",
    "field_proxy_database = pd.read_excel('Gullfaks_Data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making new copy of database\n",
    "main_database = field_proxy_database.copy()\n",
    "\n",
    "# Sampling based on cases number, seed (10) for reproducible result\n",
    "train_percent = 0.75\n",
    "val_percent = 0.25\n",
    "# test = 0.15\n",
    "\n",
    "solutionspace=3\n",
    "train = train_percent * max(main_database['Case'])-2**solutionspace\n",
    "\n",
    "# Not to include solution space edge to validation\n",
    "num_cases = np.arange(1, max(main_database['Case'])+1-2**solutionspace)\n",
    "np.random.seed(10)\n",
    "np.random.shuffle(num_cases)\n",
    "train_case, val_case = np.split(num_cases, [int(train)])\n",
    "train_case = np.append(train_case,[90, 91, 92, 93, 94, 95, 96, 97])\n",
    "\n",
    "# Labeling database based on training, validation, test cases\n",
    "main_database['Identifier'] = main_database['Case'].apply(lambda x: 'Train' if x in train_case else 'Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANNdataset (main_database, input_set, output_set):    \n",
    "    train_dataset = main_database[main_database['Identifier'] == 'Train']\n",
    "    val_dataset = main_database[main_database['Identifier'] == 'Validation']\n",
    "    \n",
    "    unneeded_columns = main_database.columns.tolist()\n",
    "    \n",
    "    for x in input_set:\n",
    "        unneeded_columns.remove(x)\n",
    "        \n",
    "    unneeded_columns.remove(output_set)\n",
    "\n",
    "    train_dataset = train_dataset.drop(unneeded_columns, axis=1)\n",
    "    val_dataset = val_dataset.drop(unneeded_columns, axis=1)\n",
    "    \n",
    "    train_label = train_dataset.pop(output_set).to_numpy()\n",
    "    train_features = train_dataset.to_numpy()\n",
    "\n",
    "    val_label = val_dataset.pop(output_set).to_numpy()\n",
    "    val_features = val_dataset.to_numpy()\n",
    "    return train_features, train_label, val_features, val_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the database for preferred proxy segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d={}\n",
    "# FOPR database\n",
    "for i in range(1, 5):\n",
    "    time_database = main_database[main_database['RealTimestep'] > (i-1)*360*2.5]\n",
    "    \n",
    "    # since it is 122 weeks, the last 2 weeks added to the last time interval\n",
    "    if i == 4:\n",
    "        time_database = time_database\n",
    "    else:\n",
    "        time_database = time_database[time_database['RealTimestep'] <= i*360*2.5]\n",
    "            \n",
    "    gas_database = time_database[time_database['FGIR [sm3/d]'] >= 1]\n",
    "    water_database = time_database[time_database['FGIR [sm3/d]'] < 1]\n",
    "    \n",
    "    input_set = ['Halfcycle day', 'qgtot', 'qwtot', 'Timestep', 'FOPR (t-1)']\n",
    "    output_set = 'FOPR [sm3/d]'\n",
    "    \n",
    "    FOPR_FgTf, FOPR_FgTl, FOPR_FgVf, FOPR_FgVl = ANNdataset(gas_database, input_set, output_set)\n",
    "    FOPR_FwTf, FOPR_FwTl, FOPR_FwVf, FOPR_FwVl = ANNdataset(water_database, input_set, output_set)\n",
    "        \n",
    "    d[\"FOPR_FgTf{0}\".format(i)] = FOPR_FgTf\n",
    "    d[\"FOPR_FgTl{0}\".format(i)] = FOPR_FgTl\n",
    "    d[\"FOPR_FgVf{0}\".format(i)] = FOPR_FgVf\n",
    "    d[\"FOPR_FgVl{0}\".format(i)] = FOPR_FgVl\n",
    "\n",
    "    d[\"FOPR_FwTf{0}\".format(i)] = FOPR_FwTf\n",
    "    d[\"FOPR_FwTl{0}\".format(i)] = FOPR_FwTl\n",
    "    d[\"FOPR_FwVf{0}\".format(i)] = FOPR_FwVf\n",
    "    d[\"FOPR_FwVl{0}\".format(i)] = FOPR_FwVl  \n",
    "    \n",
    "# CO2 database\n",
    "for i in range(0, 5):\n",
    "    if i==0:\n",
    "        time_database = main_database[main_database['RealTimestep'] > 0]\n",
    "        time_database = time_database[time_database['RealTimestep'] <= 360]\n",
    "        \n",
    "        input_set = ['Halfcycle day', 'qgtot', 'qwtot', 'Timestep', 'FCO2PR (t-1)']\n",
    "        output_set = 'FCO2PR [kg-mole/d]'\n",
    "        CO2_FTf, CO2_FTl, CO2_FVf, CO2_FVl = ANNdataset(time_database, input_set, output_set)\n",
    "\n",
    "        d[\"CO2_FTf{0}\".format(i)] = CO2_FTf\n",
    "        d[\"CO2_FTl{0}\".format(i)] = CO2_FTl\n",
    "        d[\"CO2_FVf{0}\".format(i)] = CO2_FVf\n",
    "        d[\"CO2_FVl{0}\".format(i)] = CO2_FVl\n",
    "\n",
    "    else:\n",
    "        if i == 1:\n",
    "            time_database = main_database[main_database['RealTimestep'] > 360]\n",
    "        else:\n",
    "            time_database = main_database[main_database['RealTimestep'] > (i-1)*360*2.5]\n",
    "\n",
    "        # since it is 122 weeks, the last 2 weeks added to the last time interval\n",
    "        if i == 4:\n",
    "            time_database = time_database\n",
    "        else:\n",
    "            time_database = time_database[time_database['RealTimestep'] <= i*360*2.5]\n",
    "\n",
    "        gas_database = time_database[time_database['FGIR [sm3/d]'] >= 1]\n",
    "        water_database = time_database[time_database['FGIR [sm3/d]'] < 1]\n",
    "\n",
    "        input_set = ['Halfcycle day', 'qgtot', 'qwtot', 'Timestep', 'FCO2PR (t-1)']\n",
    "        output_set = 'FCO2PR [kg-mole/d]'\n",
    "        CO2_FgTf, CO2_FgTl, CO2_FgVf, CO2_FgVl = ANNdataset(gas_database, input_set, output_set)\n",
    "        CO2_FwTf, CO2_FwTl, CO2_FwVf, CO2_FwVl = ANNdataset(water_database, input_set, output_set)\n",
    "\n",
    "        d[\"CO2_FgTf{0}\".format(i)] = CO2_FgTf\n",
    "        d[\"CO2_FgTl{0}\".format(i)] = CO2_FgTl\n",
    "        d[\"CO2_FgVf{0}\".format(i)] = CO2_FgVf\n",
    "        d[\"CO2_FgVl{0}\".format(i)] = CO2_FgVl\n",
    "\n",
    "        d[\"CO2_FwTf{0}\".format(i)] = CO2_FwTf\n",
    "        d[\"CO2_FwTl{0}\".format(i)] = CO2_FwTl\n",
    "        d[\"CO2_FwVf{0}\".format(i)] = CO2_FwVf\n",
    "        d[\"CO2_FwVl{0}\".format(i)] = CO2_FwVl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing ANN for each Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1.0e-05\n",
      "Dense layers: 2\n",
      "Nodes: 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-5c127d80c91b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mdefault_parameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1e-5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m search_result = gp_minimize(func=ANN_study, dimensions=dimensions,\n\u001b[0m\u001b[0;32m     22\u001b[0m                         \u001b[0macq_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'EI'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;31m# Expected Improvement.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m                         n_calls=80, x0=default_parameters)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\skopt\\optimizer\\gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size)\u001b[0m\n\u001b[0;32m    257\u001b[0m             noise=noise)\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m     return base_minimize(\n\u001b[0m\u001b[0;32m    260\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[0macq_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0macq_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\skopt\\optimizer\\base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[1;31m# evaluate y0 if only x0 is provided\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mx0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my0\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m         \u001b[0my0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m         \u001b[0mn_calls\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m     \u001b[1;31m# record through tell function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\skopt\\utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    801\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m             \u001b[1;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 803\u001b[1;33m             \u001b[0mobjective_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    804\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-910b5aa9614c>\u001b[0m in \u001b[0;36mANN_study\u001b[1;34m(learn_rate, layers, nodes)\u001b[0m\n\u001b[0;32m     38\u001b[0m     es = EarlyStopping(monitor='loss', mode='min', verbose=1, \n\u001b[0;32m     39\u001b[0m                        patience=patience, restore_best_weights=True)\n\u001b[1;32m---> 40\u001b[1;33m     history = model.fit(features, target, verbose=0, epochs=num_epochs, batch_size = 64,\n\u001b[0m\u001b[0;32m     41\u001b[0m                     validation_data=(val_features, val_target), callbacks=[es])\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1129\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1131\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1132\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1133\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[1;31m# Use cached evaluation data only when it's called in `Model.fit`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1348\u001b[0m       if (getattr(self, '_fit_frame', None) is not None\n\u001b[1;32m-> 1349\u001b[1;33m           \u001b[1;32mand\u001b[0m \u001b[0mtf_inspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrentframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_back\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1350\u001b[0m           and getattr(self, '_eval_data_handler', None) is not None):\n\u001b[0;32m   1351\u001b[0m         \u001b[0mdata_handler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eval_data_handler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\utils\\tf_inspect.py\u001b[0m in \u001b[0;36mcurrentframe\u001b[1;34m()\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcurrentframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m   \u001b[1;34m\"\"\"TFDecorator-aware replacement for inspect.currentframe.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_inspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis\\lib\\inspect.py\u001b[0m in \u001b[0;36mstack\u001b[1;34m(context)\u001b[0m\n\u001b[0;32m   1512\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m     \u001b[1;34m\"\"\"Return a list of records for the stack above the caller's frame.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgetouterframes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis\\lib\\inspect.py\u001b[0m in \u001b[0;36mgetouterframes\u001b[1;34m(frame, context)\u001b[0m\n\u001b[0;32m   1489\u001b[0m     \u001b[0mframelist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1490\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1491\u001b[1;33m         \u001b[0mframeinfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mgetframeinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1492\u001b[0m         \u001b[0mframelist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFrameInfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mframeinfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1493\u001b[0m         \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis\\lib\\inspect.py\u001b[0m in \u001b[0;36mgetframeinfo\u001b[1;34m(frame, context)\u001b[0m\n\u001b[0;32m   1463\u001b[0m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlineno\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1464\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1465\u001b[1;33m             \u001b[0mlines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfindsource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1466\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1467\u001b[0m             \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis\\lib\\inspect.py\u001b[0m in \u001b[0;36mfindsource\u001b[1;34m(object)\u001b[0m\n\u001b[0;32m    781\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;31m# Invalidate cache if needed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 783\u001b[1;33m         \u001b[0mlinecache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckcache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    784\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m         \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\IPython\\core\\compilerop.py\u001b[0m in \u001b[0;36mcheck_linecache_ipython\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    183\u001b[0m     \"\"\"\n\u001b[0;32m    184\u001b[0m     \u001b[1;31m# First call the original checkcache as intended\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m     \u001b[0mlinecache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_checkcache_ori\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m     \u001b[1;31m# Then, update back the cache with our data, so that tracebacks related\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;31m# to our compiled codes can be produced.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis\\lib\\linecache.py\u001b[0m in \u001b[0;36mcheckcache\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mcontinue\u001b[0m   \u001b[1;31m# no-op for files loaded via a __loader__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mstat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ANNinfo={}\n",
    "# the first 1 year interval of FCO2PR\n",
    "# Initialization before hyperparameter study\n",
    "path_best_model = \"CO2_proxy_0.keras\"\n",
    "path_best_model_performance = \"CO2_proxy_performance_0.json\"\n",
    "best_loss = 1e20\n",
    "num_epochs = 100\n",
    "features, target, val_features, val_target = d[\"CO2_FTf0\"], d[\"CO2_FTl0\"], d[\"CO2_FVf0\"], d[\"CO2_FVl0\"]\n",
    "\n",
    "# Hyper-Parameter Tuning\n",
    "# Parameter to be studied : Learning Rate, Num of Layers, Neurons, Activation Function\n",
    "dim_learn_rate = Real(low=1e-6, high=1e-2, prior='log-uniform',\n",
    "                         name='learn_rate')\n",
    "dim_layers = Integer(low=2, high=3, name='layers')\n",
    "dim_nodes = Integer(low=2, high=20, name='nodes')\n",
    "\n",
    "dimensions = [dim_learn_rate, dim_layers, dim_nodes]\n",
    "\n",
    "default_parameters = [1e-5, 2, 5]\n",
    "\n",
    "search_result = gp_minimize(func=ANN_study, dimensions=dimensions,\n",
    "                        acq_func='EI',# Expected Improvement.\n",
    "                        n_calls=80, x0=default_parameters)\n",
    "\n",
    "ANNinfo[\"Learning rate FCO2PR 0\"]=search_result.x[0]\n",
    "ANNinfo[\"Hidden layers FCO2PR 0\"]=search_result.x[1]\n",
    "ANNinfo[\"Number of nodes FCO2PR 0\"]=search_result.x[2]\n",
    "\n",
    "# Refit with higher epoch\n",
    "learn_rate = search_result.x[0]\n",
    "layers = search_result.x[1]\n",
    "nodes = search_result.x[2]\n",
    "\n",
    "ANN_model(features, target, learn_rate, layers, nodes)\n",
    "\n",
    "model = ANN_model(features, target, learn_rate, layers, nodes)\n",
    "history = model.fit(features, target, verbose=0, epochs=1500, batch_size = 64,\n",
    "                    validation_data=(val_features, val_target))\n",
    "\n",
    "model.save(path_best_model)\n",
    "\n",
    "#save the history of the best model\n",
    "ANN_performance = history.history\n",
    "temp = json.dumps(ANN_performance)\n",
    "f = open(path_best_model_performance,\"w\")\n",
    "f.write(temp)\n",
    "f.close()\n",
    "\n",
    "# Delete the Keras model with these hyper-parameters from memory.\n",
    "del model\n",
    "\n",
    "# Clear the Keras session, otherwise it will keep adding new\n",
    "# models to the same TensorFlow graph each time we create\n",
    "# a model with a different set of hyper-parameters.\n",
    "K.clear_session()\n",
    "\n",
    "# for other intervals\n",
    "for i in range(1, 5):\n",
    "    # FOPR Gas\n",
    "    # Initialization before hyperparameter study\n",
    "    path_best_model = \"FOPR_gas_proxy_{0}.keras\".format(i)\n",
    "    path_best_model_performance = \"FOPR_gas_proxy_performance_{0}.json\".format(i)\n",
    "    best_loss = 1e20\n",
    "    features, target, val_features, val_target = d[\"FOPR_FgTf{0}\".format(i)], d[\"FOPR_FgTl{0}\".format(i)], d[\"FOPR_FgVf{0}\".format(i)], d[\"FOPR_FgVl{0}\".format(i)]\n",
    "    \n",
    "    # Hyper-Parameter Tuning\n",
    "    # Parameter to be studied : Learning Rate, Num of Layers, Neurons, Activation Function\n",
    "    dim_learn_rate = Real(low=1e-6, high=1e-2, prior='log-uniform',\n",
    "                             name='learn_rate')\n",
    "    dim_layers = Integer(low=2, high=3, name='layers')\n",
    "    dim_nodes = Integer(low=2, high=20, name='nodes')\n",
    "\n",
    "    dimensions = [dim_learn_rate, dim_layers, dim_nodes]\n",
    "\n",
    "    default_parameters = [1e-5, 2, 5]\n",
    "    \n",
    "    search_result = gp_minimize(func=ANN_study, dimensions=dimensions,\n",
    "                            acq_func='EI', # Expected Improvement.\n",
    "                            n_calls=80,x0=default_parameters)\n",
    "    \n",
    "    ANNinfo[\"Learning rate FOPRg {0}\".format(i)]=search_result.x[0]\n",
    "    ANNinfo[\"Hidden layers FOPRg {0}\".format(i)]=search_result.x[1]\n",
    "    ANNinfo[\"Number of nodes FOPRg {0}\".format(i)]=search_result.x[2]\n",
    "    \n",
    "    # Refit with higher epoch\n",
    "    learn_rate = search_result.x[0]\n",
    "    layers = search_result.x[1]\n",
    "    nodes = search_result.x[2]\n",
    "\n",
    "    ANN_model(features, target, learn_rate, layers, nodes)\n",
    "\n",
    "    model = ANN_model(features, target, learn_rate, layers, nodes)\n",
    "    history = model.fit(features, target, verbose=0, epochs=1500, batch_size = 64,\n",
    "                        validation_data=(val_features, val_target))\n",
    "\n",
    "    model.save(path_best_model)\n",
    "\n",
    "    #save the history of the best model\n",
    "    ANN_performance = history.history\n",
    "    temp = json.dumps(ANN_performance)\n",
    "    f = open(path_best_model_performance,\"w\")\n",
    "    f.write(temp)\n",
    "    f.close()\n",
    "\n",
    "    # Delete the Keras model with these hyper-parameters from memory.\n",
    "    del model\n",
    "\n",
    "    # Clear the Keras session, otherwise it will keep adding new\n",
    "    # models to the same TensorFlow graph each time we create\n",
    "    # a model with a different set of hyper-parameters.\n",
    "    K.clear_session()\n",
    "    \n",
    "    \n",
    "    # FOPR Water\n",
    "    # Initialization before hyperparameter study\n",
    "    path_best_model = \"FOPR_wat_proxy_{0}.keras\".format(i)\n",
    "    path_best_model_performance = \"FOPR_wat_proxy_performance_{0}.json\".format(i)\n",
    "    best_loss = 1e20\n",
    "    features, target, val_features, val_target = d[\"FOPR_FwTf{0}\".format(i)], d[\"FOPR_FwTl{0}\".format(i)], d[\"FOPR_FwVf{0}\".format(i)], d[\"FOPR_FwVl{0}\".format(i)]\n",
    "\n",
    "    # Hyper-Parameter Tuning\n",
    "    # Parameter to be studied : Learning Rate, Num of Layers, Neurons, Activation Function\n",
    "    dim_learn_rate = Real(low=1e-6, high=1e-2, prior='log-uniform',\n",
    "                             name='learn_rate')\n",
    "    dim_layers = Integer(low=2, high=3, name='layers')\n",
    "    dim_nodes = Integer(low=2, high=20, name='nodes')\n",
    "\n",
    "    dimensions = [dim_learn_rate, dim_layers, dim_nodes]\n",
    "\n",
    "    default_parameters = [1e-5, 2, 5]\n",
    "    \n",
    "    search_result = gp_minimize(func=ANN_study, dimensions=dimensions,\n",
    "                            acq_func='EI', # Expected Improvement.\n",
    "                            n_calls=80, x0=default_parameters)\n",
    "\n",
    "    ANNinfo[\"Learning rate FOPRw {0}\".format(i)]=search_result.x[0]\n",
    "    ANNinfo[\"Hidden layers FOPRw {0}\".format(i)]=search_result.x[1]\n",
    "    ANNinfo[\"Number of nodes FOPRw {0}\".format(i)]=search_result.x[2]\n",
    "\n",
    "    # Refit with higher epoch\n",
    "    learn_rate = search_result.x[0]\n",
    "    layers = search_result.x[1]\n",
    "    nodes = search_result.x[2]\n",
    "\n",
    "    ANN_model(features, target, learn_rate, layers, nodes)\n",
    "\n",
    "    model = ANN_model(features, target, learn_rate, layers, nodes)\n",
    "    history = model.fit(features, target, verbose=0, epochs=1500, batch_size = 64,\n",
    "                        validation_data=(val_features, val_target))\n",
    "\n",
    "    model.save(path_best_model)\n",
    "\n",
    "    #save the history of the best model\n",
    "    ANN_performance = history.history\n",
    "    temp = json.dumps(ANN_performance)\n",
    "    f = open(path_best_model_performance,\"w\")\n",
    "    f.write(temp)\n",
    "    f.close()\n",
    "\n",
    "    # Delete the Keras model with these hyper-parameters from memory.\n",
    "    del model\n",
    "\n",
    "    # Clear the Keras session, otherwise it will keep adding new\n",
    "    # models to the same TensorFlow graph each time we create\n",
    "    # a model with a different set of hyper-parameters.\n",
    "    K.clear_session()\n",
    "    \n",
    "    \n",
    "\n",
    "    # FCO2PR Gas\n",
    "    # Initialization before hyperparameter study\n",
    "    path_best_model = \"CO2_gas_proxy_{0}.keras\".format(i)\n",
    "    path_best_model_performance = \"CO2_gas_proxy_performance_{0}.json\".format(i)\n",
    "    best_loss = 1e20\n",
    "    features, target, val_features, val_target = d[\"CO2_FgTf{0}\".format(i)], d[\"CO2_FgTl{0}\".format(i)], d[\"CO2_FgVf{0}\".format(i)], d[\"CO2_FgVl{0}\".format(i)]\n",
    "    \n",
    "    # Hyper-Parameter Tuning\n",
    "    # Parameter to be studied : Learning Rate, Num of Layers, Neurons, Activation Function\n",
    "    dim_learn_rate = Real(low=1e-6, high=1e-2, prior='log-uniform',\n",
    "                             name='learn_rate')\n",
    "    dim_layers = Integer(low=2, high=3, name='layers')\n",
    "    dim_nodes = Integer(low=2, high=20, name='nodes')\n",
    "\n",
    "    dimensions = [dim_learn_rate, dim_layers, dim_nodes]\n",
    "\n",
    "    default_parameters = [1e-5, 2, 5]\n",
    "    \n",
    "    search_result = gp_minimize(func=ANN_study, dimensions=dimensions,\n",
    "                            acq_func='EI',# Expected Improvement.\n",
    "                            n_calls=80, x0=default_parameters)\n",
    "    \n",
    "    ANNinfo[\"Learning rate FCO2PRg {0}\".format(i)]=search_result.x[0]\n",
    "    ANNinfo[\"Hidden layers FCO2PRg {0}\".format(i)]=search_result.x[1]\n",
    "    ANNinfo[\"Number of nodes FCO2PRg {0}\".format(i)]=search_result.x[2]\n",
    "    \n",
    "    # Refit with higher epoch\n",
    "    learn_rate = search_result.x[0]\n",
    "    layers = search_result.x[1]\n",
    "    nodes = search_result.x[2]\n",
    "\n",
    "    ANN_model(features, target, learn_rate, layers, nodes)\n",
    "\n",
    "    model = ANN_model(features, target, learn_rate, layers, nodes)\n",
    "    history = model.fit(features, target, verbose=0, epochs=1500, batch_size = 64,\n",
    "                        validation_data=(val_features, val_target))\n",
    "\n",
    "    model.save(path_best_model)\n",
    "\n",
    "    #save the history of the best model\n",
    "    ANN_performance = history.history\n",
    "    temp = json.dumps(ANN_performance)\n",
    "    f = open(path_best_model_performance,\"w\")\n",
    "    f.write(temp)\n",
    "    f.close()\n",
    "\n",
    "    # Delete the Keras model with these hyper-parameters from memory.\n",
    "    del model\n",
    "\n",
    "    # Clear the Keras session, otherwise it will keep adding new\n",
    "    # models to the same TensorFlow graph each time we create\n",
    "    # a model with a different set of hyper-parameters.\n",
    "    K.clear_session()\n",
    "    \n",
    "    \n",
    "    # FCO2PR Water\n",
    "    # Initialization before hyperparameter study\n",
    "    path_best_model = \"CO2_wat_proxy_{0}.keras\".format(i)\n",
    "    path_best_model_performance = \"CO2_wat_proxy_performance_{0}.json\".format(i)\n",
    "    best_loss = 1e20\n",
    "    features, target, val_features, val_target = d[\"CO2_FwTf{0}\".format(i)], d[\"CO2_FwTl{0}\".format(i)], d[\"CO2_FwVf{0}\".format(i)], d[\"CO2_FwVl{0}\".format(i)]\n",
    "\n",
    "    # Hyper-Parameter Tuning\n",
    "    # Parameter to be studied : Learning Rate, Num of Layers, Neurons, Activation Function\n",
    "    dim_learn_rate = Real(low=1e-6, high=1e-2, prior='log-uniform',\n",
    "                             name='learn_rate')\n",
    "    dim_layers = Integer(low=2, high=3, name='layers')\n",
    "    dim_nodes = Integer(low=2, high=20, name='nodes')\n",
    "\n",
    "    dimensions = [dim_learn_rate, dim_layers, dim_nodes]\n",
    "\n",
    "    default_parameters = [1e-5, 2, 5]\n",
    "    \n",
    "    search_result = gp_minimize(func=ANN_study, dimensions=dimensions,\n",
    "                            acq_func='EI',# Expected Improvement.\n",
    "                            n_calls=80, x0=default_parameters)\n",
    "    \n",
    "    ANNinfo[\"Learning rate FCO2PRw {0}\".format(i)]=search_result.x[0]\n",
    "    ANNinfo[\"Hidden layers FCO2PRw {0}\".format(i)]=search_result.x[1]\n",
    "    ANNinfo[\"Number of nodes FCO2PRw {0}\".format(i)]=search_result.x[2]\n",
    "\n",
    "    # Refit with higher epoch\n",
    "    learn_rate = search_result.x[0]\n",
    "    layers = search_result.x[1]\n",
    "    nodes = search_result.x[2]\n",
    "\n",
    "    ANN_model(features, target, learn_rate, layers, nodes)\n",
    "\n",
    "    model = ANN_model(features, target, learn_rate, layers, nodes)\n",
    "    history = model.fit(features, target, verbose=0, epochs=1500, batch_size = 64,\n",
    "                        validation_data=(val_features, val_target))\n",
    "\n",
    "    model.save(path_best_model)\n",
    "\n",
    "    #save the history of the best model\n",
    "    ANN_performance = history.history\n",
    "    temp = json.dumps(ANN_performance)\n",
    "    f = open(path_best_model_performance,\"w\")\n",
    "    f.write(temp)\n",
    "    f.close()\n",
    "\n",
    "    # Delete the Keras model with these hyper-parameters from memory.\n",
    "    del model\n",
    "\n",
    "    # Clear the Keras session, otherwise it will keep adding new\n",
    "    # models to the same TensorFlow graph each time we create\n",
    "    # a model with a different set of hyper-parameters.\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing topology of every ANN used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Learning rate FCO2PR 0': 0.005375194223114987,\n",
       " 'Hidden layers FCO2PR 0': 3,\n",
       " 'Number of nodes FCO2PR 0': 17,\n",
       " 'Learning rate FOPRg 1': 0.008297857140864767,\n",
       " 'Hidden layers FOPRg 1': 3,\n",
       " 'Number of nodes FOPRg 1': 20,\n",
       " 'Learning rate FOPRw 1': 0.01,\n",
       " 'Hidden layers FOPRw 1': 3,\n",
       " 'Number of nodes FOPRw 1': 20,\n",
       " 'Learning rate FCO2PRg 1': 0.004766816837932449,\n",
       " 'Hidden layers FCO2PRg 1': 3,\n",
       " 'Number of nodes FCO2PRg 1': 20,\n",
       " 'Learning rate FCO2PRw 1': 0.008615316703813342,\n",
       " 'Hidden layers FCO2PRw 1': 3,\n",
       " 'Number of nodes FCO2PRw 1': 12,\n",
       " 'Learning rate FOPRg 2': 0.003353664936997718,\n",
       " 'Hidden layers FOPRg 2': 3,\n",
       " 'Number of nodes FOPRg 2': 20,\n",
       " 'Learning rate FOPRw 2': 0.0018774388723190047,\n",
       " 'Hidden layers FOPRw 2': 3,\n",
       " 'Number of nodes FOPRw 2': 20,\n",
       " 'Learning rate FCO2PRg 2': 0.003534008038365451,\n",
       " 'Hidden layers FCO2PRg 2': 3,\n",
       " 'Number of nodes FCO2PRg 2': 20,\n",
       " 'Learning rate FCO2PRw 2': 0.01,\n",
       " 'Hidden layers FCO2PRw 2': 2,\n",
       " 'Number of nodes FCO2PRw 2': 20,\n",
       " 'Learning rate FOPRg 3': 0.0011053610889393006,\n",
       " 'Hidden layers FOPRg 3': 3,\n",
       " 'Number of nodes FOPRg 3': 20,\n",
       " 'Learning rate FOPRw 3': 0.00986841521559379,\n",
       " 'Hidden layers FOPRw 3': 2,\n",
       " 'Number of nodes FOPRw 3': 16,\n",
       " 'Learning rate FCO2PRg 3': 0.01,\n",
       " 'Hidden layers FCO2PRg 3': 3,\n",
       " 'Number of nodes FCO2PRg 3': 20,\n",
       " 'Learning rate FCO2PRw 3': 0.0072278363592229306,\n",
       " 'Hidden layers FCO2PRw 3': 3,\n",
       " 'Number of nodes FCO2PRw 3': 17,\n",
       " 'Learning rate FOPRg 4': 0.01,\n",
       " 'Hidden layers FOPRg 4': 3,\n",
       " 'Number of nodes FOPRg 4': 20,\n",
       " 'Learning rate FOPRw 4': 0.01,\n",
       " 'Hidden layers FOPRw 4': 3,\n",
       " 'Number of nodes FOPRw 4': 20,\n",
       " 'Learning rate FCO2PRg 4': 0.0015402000092612665,\n",
       " 'Hidden layers FCO2PRg 4': 3,\n",
       " 'Number of nodes FCO2PRg 4': 20,\n",
       " 'Learning rate FCO2PRw 4': 0.01,\n",
       " 'Hidden layers FCO2PRw 4': 2,\n",
       " 'Number of nodes FCO2PRw 4': 16}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANNinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing ANN performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FCO2PR_0': array([9.94453980e-01, 9.81189831e-01, 9.03202909e-03, 7.10511186e-04,\n",
      "       5.56943402e-07, 2.00711551e-02, 5.93281775e-04, 3.70031918e-07]), 'FOPR_g1': array([9.88189921e-01, 9.76926501e-01, 1.23226737e-01, 8.33881733e-03,\n",
      "       1.17513252e-05, 1.10247019e-01, 9.78371654e-03, 9.93735923e-06]), 'FOPR_w1': array([9.90415539e-01, 9.81849668e-01, 8.80228627e-02, 1.23395740e-02,\n",
      "       1.55006371e-05, 9.88552103e-02, 1.35195010e-02, 3.33408584e-07]), 'FCO2PR_g1': array([9.91641305e-01, 9.66770025e-01, 3.40244726e-02, 3.72719558e-03,\n",
      "       1.31318028e-06, 7.25429134e-02, 5.39173029e-03, 5.28279535e-05]), 'FCO2PR_w1': array([9.78498520e-01, 9.66505966e-01, 5.59501574e-02, 7.24980838e-03,\n",
      "       1.26599306e-06, 5.28169306e-02, 7.97698068e-03, 2.82411248e-05]), 'FOPR_g2': array([9.65769471e-01, 9.12688019e-01, 8.94156482e-02, 1.39511549e-02,\n",
      "       8.41347733e-05, 8.70263895e-02, 1.92950341e-02, 8.12994539e-05]), 'FOPR_w2': array([9.77918932e-01, 9.48416338e-01, 8.80936509e-02, 1.17327554e-02,\n",
      "       4.04778637e-06, 1.16454516e-01, 1.69990756e-02, 2.07142949e-04]), 'FCO2PR_g2': array([9.81772347e-01, 9.66476833e-01, 9.10719207e-02, 1.32778215e-02,\n",
      "       2.95168413e-05, 8.00884306e-02, 1.45395732e-02, 3.01466909e-05]), 'FCO2PR_w2': array([9.75907002e-01, 9.71919934e-01, 8.00195440e-02, 1.29561023e-02,\n",
      "       2.89232533e-05, 5.72345467e-02, 1.18809436e-02, 1.69149943e-05]), 'FOPR_g3': array([9.81252587e-01, 9.54861843e-01, 3.45242946e-02, 6.29284126e-03,\n",
      "       5.71134902e-06, 5.46312161e-02, 8.59418776e-03, 4.79676379e-05]), 'FOPR_w3': array([9.72598838e-01, 9.59684678e-01, 5.84413307e-02, 8.85721657e-03,\n",
      "       2.19088884e-05, 5.47275511e-02, 9.99894068e-03, 4.21264802e-06]), 'FCO2PR_g3': array([9.90998321e-01, 9.87246457e-01, 6.86122578e-02, 1.21200660e-02,\n",
      "       1.50133132e-05, 5.31214608e-02, 1.14601047e-02, 3.21496541e-05]), 'FCO2PR_w3': array([9.88805411e-01, 9.87181853e-01, 7.72476142e-02, 1.20542308e-02,\n",
      "       1.08734973e-05, 6.17186238e-02, 1.14811303e-02, 5.35781745e-07]), 'FOPR_g4': array([9.87716341e-01, 9.64559397e-01, 1.88899044e-02, 2.90816600e-03,\n",
      "       4.27034865e-08, 2.02179706e-02, 4.54583427e-03, 2.12275486e-05]), 'FOPR_w4': array([9.89731235e-01, 9.72517012e-01, 1.81753962e-02, 3.68008949e-03,\n",
      "       5.22917307e-06, 1.90979523e-02, 4.56371927e-03, 1.28635308e-05]), 'FCO2PR_g4': array([9.87598438e-01, 9.77451947e-01, 9.12232698e-02, 1.28854209e-02,\n",
      "       1.70577161e-05, 1.07127431e-01, 1.36054119e-02, 1.67452990e-04]), 'FCO2PR_w4': array([9.67701565e-01, 9.73529978e-01, 1.41269050e-01, 1.54874104e-02,\n",
      "       3.87191458e-05, 1.37199175e-01, 1.26848844e-02, 3.32343095e-06])}\n"
     ]
    }
   ],
   "source": [
    "# Error distribution and proxy performance function for test data\n",
    "def plot_train_performance(model, train_input, train_output, val_input, val_output, lims):\n",
    "    # model = the ANN model (fitted)\n",
    "    # train_input = input for the ANN from training database\n",
    "    # train_output = output of the training database\n",
    "    # val_input = input for the ANN from validation database\n",
    "    # val_output = output of the validation database\n",
    "    # lims = 2 points [min,max] for the plot boundary\n",
    "\n",
    "    # Calculate test data with the model\n",
    "    train_predictions = model.predict(train_input).flatten()\n",
    "    val_predictions = model.predict(val_input).flatten()\n",
    "    \n",
    "    # Calculate R^2\n",
    "    r2_train = r2_score(train_output, train_predictions)\n",
    "    r2_val = r2_score(val_output, val_predictions)\n",
    "    \n",
    "    # Calculate Training Absolute Error (AE)\n",
    "    ape_train = abs(train_output-train_predictions)\n",
    "    max_ape_train = max(ape_train)\n",
    "    mean_ape_train = statistics.mean(ape_train)\n",
    "    min_ape_train = min(ape_train)\n",
    "    \n",
    "    # Calculate Validation Absolute Error (AE)\n",
    "    ape_val = abs(val_output-val_predictions)\n",
    "    max_ape_val = max(ape_val)\n",
    "    mean_ape_val = statistics.mean(ape_val)\n",
    "    min_ape_val = min(ape_val)\n",
    "    \n",
    "    theresult = np.array((r2_train,r2_val,max_ape_train, mean_ape_train, min_ape_train,max_ape_val, mean_ape_val, min_ape_val))\n",
    "    return theresult\n",
    "\n",
    "lims = [0,1]\n",
    "resultdatabase={}\n",
    "# FCO2PR 0\n",
    "# Initialization before hyperparameter study\n",
    "path_best_model = \"CO2_proxy_0.keras\"\n",
    "path_best_model_performance = \"CO2_proxy_performance_0.json\"\n",
    "features, target, val_features, val_target = d[\"CO2_FTf0\"], d[\"CO2_FTl0\"], d[\"CO2_FVf0\"], d[\"CO2_FVl0\"]\n",
    "\n",
    "# Opening model\n",
    "best_model = load_model(path_best_model)\n",
    "\n",
    "# Opening JSON file\n",
    "f = open(path_best_model_performance)\n",
    "best_model_performance = json.load(f)\n",
    "f.close()\n",
    "\n",
    "resultdatabase[\"FCO2PR_0\"] = plot_train_performance(best_model, features, target, val_features, val_target, lims)\n",
    "\n",
    "\n",
    "for i in range(1, 5):\n",
    "    # FOPR Gas\n",
    "    # Initialization before hyperparameter study\n",
    "    path_best_model = \"FOPR_gas_proxy_{0}.keras\".format(i)\n",
    "    path_best_model_performance = \"FOPR_gas_proxy_performance_{0}.json\".format(i)\n",
    "    features, target, val_features, val_target = d[\"FOPR_FgTf{0}\".format(i)], d[\"FOPR_FgTl{0}\".format(i)], d[\"FOPR_FgVf{0}\".format(i)], d[\"FOPR_FgVl{0}\".format(i)]\n",
    "    \n",
    "    # Opening model\n",
    "    best_model = load_model(path_best_model)\n",
    "\n",
    "    # Opening JSON file\n",
    "    f = open(path_best_model_performance)\n",
    "    best_model_performance = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    resultdatabase[\"FOPR_g{0}\".format(i)]=plot_train_performance(best_model, features, target, val_features, val_target, lims)\n",
    "    \n",
    "    # FOPR Water\n",
    "    # Initialization before hyperparameter study\n",
    "    path_best_model = \"FOPR_wat_proxy_{0}.keras\".format(i)\n",
    "    path_best_model_performance = \"FOPR_wat_proxy_performance_{0}.json\".format(i)\n",
    "    features, target, val_features, val_target = d[\"FOPR_FwTf{0}\".format(i)], d[\"FOPR_FwTl{0}\".format(i)], d[\"FOPR_FwVf{0}\".format(i)], d[\"FOPR_FwVl{0}\".format(i)]\n",
    "\n",
    "    # Opening model\n",
    "    best_model = load_model(path_best_model)\n",
    "\n",
    "    # Opening JSON file\n",
    "    f = open(path_best_model_performance)\n",
    "    best_model_performance = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    resultdatabase[\"FOPR_w{0}\".format(i)]=plot_train_performance(best_model, features, target, val_features, val_target, lims)\n",
    "\n",
    "    # FCO2PR Gas\n",
    "    # Initialization before hyperparameter study\n",
    "    path_best_model = \"CO2_gas_proxy_{0}.keras\".format(i)\n",
    "    path_best_model_performance = \"CO2_gas_proxy_performance_{0}.json\".format(i)\n",
    "    features, target, val_features, val_target = d[\"CO2_FgTf{0}\".format(i)], d[\"CO2_FgTl{0}\".format(i)], d[\"CO2_FgVf{0}\".format(i)], d[\"CO2_FgVl{0}\".format(i)]\n",
    "    \n",
    "    # Opening model\n",
    "    best_model = load_model(path_best_model)\n",
    "\n",
    "    # Opening JSON file\n",
    "    f = open(path_best_model_performance)\n",
    "    best_model_performance = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    resultdatabase[\"FCO2PR_g{0}\".format(i)]=plot_train_performance(best_model, features, target, val_features, val_target, lims)\n",
    "    \n",
    "    # FCO2PR Water\n",
    "    # Initialization before hyperparameter study\n",
    "    path_best_model = \"CO2_wat_proxy_{0}.keras\".format(i)\n",
    "    path_best_model_performance = \"CO2_wat_proxy_performance_{0}.json\".format(i)\n",
    "    features, target, val_features, val_target = d[\"CO2_FwTf{0}\".format(i)], d[\"CO2_FwTl{0}\".format(i)], d[\"CO2_FwVf{0}\".format(i)], d[\"CO2_FwVl{0}\".format(i)]\n",
    "\n",
    "    # Opening model\n",
    "    best_model = load_model(path_best_model)\n",
    "\n",
    "    # Opening JSON file\n",
    "    f = open(path_best_model_performance)\n",
    "    best_model_performance = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    resultdatabase[\"FCO2PR_w{0}\".format(i)]=plot_train_performance(best_model, features, target, val_features, val_target, lims)\n",
    "\n",
    "print(resultdatabase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the whole data using combined proxy model (Training, Validation, Blind Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-98cc9d91e9e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Importing database, note that all data is inserted in this database already\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mblind_proxy_database\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Gullfaks_Data_blind.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Importing database, note that all data is inserted in this database already\n",
    "blind_proxy_database = pd.read_excel('Gullfaks_Data_blind.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple 1 run, Choose Case ID to be tested in Blind Test\n",
    "Range 1- 97 --> Trained data <br>\n",
    "Range 98 - 109 --> Blind Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put Case ID here\n",
    "Case_ID=70\n",
    "\n",
    "blind_database = blind_proxy_database[blind_proxy_database['Case'] == Case_ID].reset_index()\n",
    "\n",
    "# Making dataset comparison for FOPR proxy\n",
    "FOPR_blind_label = blind_database['FOPR [sm3/d]'].to_numpy()\n",
    "\n",
    "# Making dataset comparison for FCO2PR proxy\n",
    "CO2_blind_label = blind_database['FCO2PR [kg-mole/d]'].to_numpy()\n",
    "\n",
    "# Loading the model\n",
    "co2_model0 = load_model(\"CO2_proxy_0.keras\")\n",
    "\n",
    "fopr_gas_model1 = load_model(\"FOPR_gas_proxy_1.keras\")\n",
    "fopr_wat_model1 = load_model(\"FOPR_wat_proxy_1.keras\")\n",
    "co2_gas_model1 = load_model(\"CO2_gas_proxy_1.keras\")\n",
    "co2_wat_model1 = load_model(\"CO2_wat_proxy_1.keras\")\n",
    "\n",
    "fopr_gas_model2 = load_model(\"FOPR_gas_proxy_2.keras\")\n",
    "fopr_wat_model2 = load_model(\"FOPR_wat_proxy_2.keras\")\n",
    "co2_gas_model2 = load_model(\"CO2_gas_proxy_2.keras\")\n",
    "co2_wat_model2 = load_model(\"CO2_wat_proxy_2.keras\")\n",
    "\n",
    "fopr_gas_model3 = load_model(\"FOPR_gas_proxy_3.keras\")\n",
    "fopr_wat_model3 = load_model(\"FOPR_wat_proxy_3.keras\")\n",
    "co2_gas_model3 = load_model(\"CO2_gas_proxy_3.keras\")\n",
    "co2_wat_model3 = load_model(\"CO2_wat_proxy_3.keras\")\n",
    "\n",
    "fopr_gas_model4 = load_model(\"FOPR_gas_proxy_4.keras\")\n",
    "fopr_wat_model4 = load_model(\"FOPR_wat_proxy_4.keras\")\n",
    "co2_gas_model4 = load_model(\"CO2_gas_proxy_4.keras\")\n",
    "co2_wat_model4 = load_model(\"CO2_wat_proxy_4.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Defining temporary storage and variables\n",
    "ts = 1\n",
    "proxy_result = np.empty(shape=(1,5))\n",
    "FOPR_before = 0.491075203\n",
    "CO2_before = 0.003634399\n",
    "\n",
    "# Taking the blind test condition\n",
    "halfcycle_blind = blind_database['Halfcycle day'][0]\n",
    "qg_blind = blind_database['qgtot'][0]\n",
    "qw_blind = blind_database['qwtot'][0]\n",
    "\n",
    "# Looping through 122 timesteps\n",
    "for ts in range (1, 123):\n",
    "    ts_norm = (ts-1)/(122-1)\n",
    "    CO2_input = np.array([[halfcycle_blind, qg_blind, qw_blind, ts_norm, CO2_before]])\n",
    "    FOPR_input = np.array([[halfcycle_blind, qg_blind, qw_blind, ts_norm, FOPR_before]])\n",
    "        \n",
    "    # Determine whether to use gas or water proxy\n",
    "    temp = math.floor((ts-1)/(halfcycle_blind*9+3))\n",
    "    if (temp % 2) == 0:\n",
    "        if ts <= 12:\n",
    "            FOPR = fopr_gas_model1.predict(FOPR_input)\n",
    "            CO2 = co2_model0.predict(CO2_input)\n",
    "        elif ts <= 30:\n",
    "            FOPR = fopr_gas_model1.predict(FOPR_input)\n",
    "            CO2 = co2_gas_model1.predict(CO2_input)\n",
    "        elif ts <= 60:\n",
    "            FOPR = fopr_gas_model2.predict(FOPR_input)\n",
    "            CO2 = co2_gas_model2.predict(CO2_input)\n",
    "        elif ts <= 90:\n",
    "            FOPR = fopr_gas_model3.predict(FOPR_input)\n",
    "            CO2 = co2_gas_model3.predict(CO2_input)\n",
    "        else:\n",
    "            FOPR = fopr_gas_model4.predict(FOPR_input)\n",
    "            CO2 = co2_gas_model4.predict(CO2_input)\n",
    "    else:\n",
    "        if ts <= 12:\n",
    "            FOPR = fopr_wat_model1.predict(FOPR_input)\n",
    "            CO2 = co2_model0.predict(CO2_input)\n",
    "        elif ts <= 30:\n",
    "            FOPR = fopr_wat_model1.predict(FOPR_input)\n",
    "            CO2 = co2_wat_model1.predict(CO2_input)\n",
    "        elif ts <= 60:\n",
    "            FOPR = fopr_wat_model2.predict(FOPR_input)\n",
    "            CO2 = co2_wat_model2.predict(CO2_input)\n",
    "        elif ts <= 90:\n",
    "            FOPR = fopr_wat_model3.predict(FOPR_input)\n",
    "            CO2 = co2_wat_model3.predict(CO2_input)\n",
    "        else:\n",
    "            FOPR = fopr_wat_model4.predict(FOPR_input)\n",
    "            CO2 = co2_wat_model4.predict(CO2_input)\n",
    "    \n",
    "    # transfer value from array to one value\n",
    "    FOPR = FOPR[0,0]\n",
    "    CO2 = CO2[0,0]\n",
    "    \n",
    "    result = np.array([[ts_norm, CO2_before, CO2, FOPR_before, FOPR]])\n",
    "    proxy_result = np.append(proxy_result, result, axis = 0)\n",
    "    \n",
    "    CO2_before = CO2\n",
    "    FOPR_before = FOPR\n",
    "    \n",
    "# Throwing dummy value in index 0\n",
    "proxy_result = proxy_result[1:,:]\n",
    "\n",
    "# Plotting the result\n",
    "real_timestep = proxy_result[:,0]*(3660-30)+30\n",
    "real_CO2_eclipse = CO2_blind_label[:]*(62301.45703+0)+0\n",
    "real_CO2_proxy = proxy_result[:,2]*(62301.45703+0)+0\n",
    "real_FOPR_eclipse = FOPR_blind_label[:]*(1558.028809-0)+0\n",
    "real_FOPR_proxy = proxy_result[:,4]*(1558.028809-0)+0\n",
    "\n",
    "plt.figure(20)\n",
    "if Case_ID > 86:\n",
    "    plt.title('Blind Test Performance')\n",
    "elif Case_ID in val_case:\n",
    "    plt.title('Validation Data Performance')\n",
    "else:\n",
    "    plt.title('Training Data Performance')\n",
    "plt.xlabel('Timestep (month)')\n",
    "plt.ylabel('CO2 Rate (kg-mole/day)')\n",
    "plt.plot(real_timestep[:], real_CO2_eclipse[:], label='Eclipse', color='black', linewidth=3)\n",
    "plt.scatter(real_timestep[:], real_CO2_proxy[:], label='Proxy', linestyle='-', color='red', alpha=0.5)\n",
    "plt.legend(['Eclipse', 'Proxy'], loc='lower right')\n",
    "plt.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0,0))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(21)\n",
    "if Case_ID > 68:\n",
    "    plt.title('Blind Test Performance')\n",
    "elif Case_ID in val_case:\n",
    "    plt.title('Validation Data Performance')\n",
    "else:\n",
    "    plt.title('Training Data Performance')\n",
    "plt.xlabel('Timestep (month)')\n",
    "plt.ylabel('FOPR (sm$^3$/day)')\n",
    "plt.plot(real_timestep[:], real_FOPR_eclipse[:], label='Eclipse', color='black', linewidth=3)\n",
    "plt.scatter(real_timestep[:], real_FOPR_proxy[:], label='Proxy', linestyle='-', color='red', alpha=0.5)\n",
    "plt.legend(['Eclipse', 'Proxy'], loc='upper right')\n",
    "plt.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run all data\n",
    "All data that we have in the database (Training, Validation, Blind Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-b8e6dc2cb271>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m                 \u001b[0mCO2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mco2_gas_model2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCO2_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mts\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m90\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m                 \u001b[0mFOPR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfopr_gas_model3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFOPR_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m                 \u001b[0mCO2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mco2_gas_model3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCO2_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1596\u001b[0m                         '. Consider setting it to AutoShardPolicy.DATA.')\n\u001b[0;32m   1597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1598\u001b[1;33m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[0;32m   1599\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1600\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    351\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mflat_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m     \u001b[0mindices_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mflat_map\u001b[1;34m(self, map_func)\u001b[0m\n\u001b[0;32m   1835\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1836\u001b[0m     \"\"\"\n\u001b[1;32m-> 1837\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mFlatMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1838\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1839\u001b[0m   def interleave(self,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func)\u001b[0m\n\u001b[0;32m   4282\u001b[0m     \u001b[1;34m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4283\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4284\u001b[1;33m     self._map_func = StructuredFunctionWrapper(\n\u001b[0m\u001b[0;32m   4285\u001b[0m         map_func, self._transformation_name(), dataset=input_dataset)\n\u001b[0;32m   4286\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDatasetSpec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m   3523\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3524\u001b[0m         \u001b[1;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3525\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3526\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3527\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3049\u001b[0m       \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0minputs\u001b[0m \u001b[0mto\u001b[0m \u001b[0mspecialize\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3050\u001b[0m     \"\"\"\n\u001b[1;32m-> 3051\u001b[1;33m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[0;32m   3052\u001b[0m         *args, **kwargs)\n\u001b[0;32m   3053\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3017\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3018\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3019\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3020\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3021\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3196\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   3516\u001b[0m           attributes=defun_kwargs)\n\u001b[0;32m   3517\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=missing-docstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3518\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3519\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3520\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   3451\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3453\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3454\u001b[0m       \u001b[1;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3455\u001b[0m       \u001b[1;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    665\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 667\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    668\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m   \u001b[1;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 478\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    479\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mslice_batch_indices\u001b[1;34m(indices)\u001b[0m\n\u001b[0;32m    340\u001b[0m           first_k_indices, [num_full_batches, batch_size])\n\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m       \u001b[0mflat_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_k_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_partial_batch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         index_remainder = dataset_ops.DatasetV2.from_tensors(array_ops.slice(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    689\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \"\"\"\n\u001b[1;32m--> 691\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m   \u001b[1;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, element)\u001b[0m\n\u001b[0;32m   3165\u001b[0m           tensor_shape.dimension_value(t.get_shape()[0])))\n\u001b[0;32m   3166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3167\u001b[1;33m     variant_tensor = gen_dataset_ops.tensor_slice_dataset(\n\u001b[0m\u001b[0;32m   3168\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3169\u001b[0m         output_shapes=structure.get_flat_tensor_shapes(self._structure))\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36mtensor_slice_dataset\u001b[1;34m(components, output_shapes, name)\u001b[0m\n\u001b[0;32m   6771\u001b[0m         \"'tensor_slice_dataset' Op, not %r.\" % output_shapes)\n\u001b[0;32m   6772\u001b[0m   \u001b[0moutput_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"output_shapes\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_s\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutput_shapes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6773\u001b[1;33m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[0;32m   6774\u001b[0m         \u001b[1;34m\"TensorSliceDataset\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomponents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6775\u001b[0m                               output_shapes=output_shapes, name=name)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    746\u001b[0m       \u001b[1;31m# Add Op to graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m       \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[0;32m    749\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    588\u001b[0m       \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    591\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         compute_device)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3526\u001b[0m     \u001b[1;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3527\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3528\u001b[1;33m       ret = Operation(\n\u001b[0m\u001b[0;32m   3529\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3530\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   2013\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mop_def\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2014\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2015\u001b[1;33m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0m\u001b[0;32m   2016\u001b[0m                                 control_input_ops, op_def)\n\u001b[0;32m   2017\u001b[0m       \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1824\u001b[0m   \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_reconstruct_sequence_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1826\u001b[1;33m   op_desc = pywrap_tf_session.TF_NewOperation(graph._c_graph,\n\u001b[0m\u001b[0;32m   1827\u001b[0m                                               \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1828\u001b[0m                                               compat.as_str(node_def.name))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "proxy_result = np.empty(shape=(1,3))\n",
    "\n",
    "for Case_ID in range (1,110):\n",
    "    blind_database = blind_proxy_database[blind_proxy_database['Case'] == Case_ID].reset_index()\n",
    "\n",
    "    # Making dataset for FOPR proxy\n",
    "    FOPR_blind_label = blind_database['FOPR [sm3/d]'].to_numpy()\n",
    "\n",
    "    # Making dataset for FCO2PR proxy\n",
    "    CO2_blind_label = blind_database['FCO2PR [kg-mole/d]'].to_numpy()\n",
    "        \n",
    "    # Defining temporary storage and variables\n",
    "    ts = 1\n",
    "    FOPR_before = 0.491075203\n",
    "    CO2_before = 0.003634399\n",
    "\n",
    "    # Taking the blind test condition\n",
    "    halfcycle_blind = blind_database['Halfcycle day'][0]\n",
    "    qg_blind = blind_database['qgtot'][0]\n",
    "    qw_blind = blind_database['qwtot'][0]\n",
    "    \n",
    "    # Looping through 122 timesteps\n",
    "    for ts in range (1, 123):\n",
    "        ts_norm = (ts-1)/(122-1)\n",
    "        CO2_input = np.array([[halfcycle_blind, qg_blind, qw_blind, ts_norm, CO2_before]])\n",
    "        FOPR_input = np.array([[halfcycle_blind, qg_blind, qw_blind, ts_norm, FOPR_before]])\n",
    "\n",
    "        # Determine whether to use gas or water proxy\n",
    "        temp = math.floor((ts-1)/(halfcycle_blind*9+3))\n",
    "        if (temp % 2) == 0:\n",
    "            if ts <= 12:\n",
    "                FOPR = fopr_gas_model1.predict(FOPR_input)\n",
    "                CO2 = co2_model0.predict(CO2_input)\n",
    "            elif ts <= 30:\n",
    "                FOPR = fopr_gas_model1.predict(FOPR_input)\n",
    "                CO2 = co2_gas_model1.predict(CO2_input)\n",
    "            elif ts <= 60:\n",
    "                FOPR = fopr_gas_model2.predict(FOPR_input)\n",
    "                CO2 = co2_gas_model2.predict(CO2_input)\n",
    "            elif ts <= 90:\n",
    "                FOPR = fopr_gas_model3.predict(FOPR_input)\n",
    "                CO2 = co2_gas_model3.predict(CO2_input)\n",
    "            else:\n",
    "                FOPR = fopr_gas_model4.predict(FOPR_input)\n",
    "                CO2 = co2_gas_model4.predict(CO2_input)\n",
    "        else:\n",
    "            if ts <= 12:\n",
    "                FOPR = fopr_wat_model1.predict(FOPR_input)\n",
    "                CO2 = co2_model0.predict(CO2_input)\n",
    "            elif ts <= 30:\n",
    "                FOPR = fopr_wat_model1.predict(FOPR_input)\n",
    "                CO2 = co2_wat_model1.predict(CO2_input)\n",
    "            elif ts <= 60:\n",
    "                FOPR = fopr_wat_model2.predict(FOPR_input)\n",
    "                CO2 = co2_wat_model2.predict(CO2_input)\n",
    "            elif ts <= 90:\n",
    "                FOPR = fopr_wat_model3.predict(FOPR_input)\n",
    "                CO2 = co2_wat_model3.predict(CO2_input)\n",
    "            else:\n",
    "                FOPR = fopr_wat_model4.predict(FOPR_input)\n",
    "                CO2 = co2_wat_model4.predict(CO2_input)\n",
    "\n",
    "        # transfer value from array to one value\n",
    "        FOPR = FOPR[0,0]\n",
    "        CO2 = CO2[0,0]\n",
    "        \n",
    "        # Denormalization\n",
    "        ts_real = ts_norm*(3660-30)+30\n",
    "        real_CO2_proxy = CO2*(62301.45703+0)+0\n",
    "        real_FOPR_proxy = FOPR*(1558.028809-0)+0\n",
    "        \n",
    "        result = np.array([[ts_real, real_CO2_proxy, real_FOPR_proxy]])\n",
    "        proxy_result = np.append(proxy_result, result, axis = 0)\n",
    "\n",
    "        CO2_before = CO2\n",
    "        FOPR_before = FOPR\n",
    "\n",
    "# Throwing dummy value in index 0\n",
    "proxy_result = proxy_result[1:,:]\n",
    "\n",
    "ProxyResult = pd.DataFrame(proxy_result, columns=['Timestep', 'CO2 Proxy', 'FOPR Proxy'])\n",
    "\n",
    "ProxyResult.to_excel(\"ProxyAllRun.xlsx\",sheet_name='RunResults')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Study\n",
    "Performing optimization study using the proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Proxy defined as functions\n",
    "def oilproxy (halfcycle,qg,qw):\n",
    "    #Normalization\n",
    "    halfcycle_norm = (halfcycle-3)/(12-3)\n",
    "    qg_norm = (qg-1)/(2-1)\n",
    "    qw_norm = (qw-3000)/(9000-3000)\n",
    "\n",
    "    # Defining temporary storage and variables\n",
    "    ts = 1\n",
    "    proxy_result = np.empty(shape=(1,2))\n",
    "    FOPR_before = 0.491075203\n",
    "\n",
    "    # Looping through 122 timesteps\n",
    "    for ts in range (1, 123):\n",
    "        ts_norm = (ts-1)/(122-1)\n",
    "        FOPR_input = np.array([[halfcycle_norm, qg_norm, qw_norm, ts_norm, FOPR_before]])\n",
    "\n",
    "        # Determine whether to use gas or water proxy\n",
    "        temp = math.floor((ts-1)/(halfcycle_norm*9+3))\n",
    "        if (temp % 2) == 0:\n",
    "            if ts <= 12:\n",
    "                FOPR = fopr_gas_model1.predict(FOPR_input)\n",
    "            elif ts <= 30:\n",
    "                FOPR = fopr_gas_model1.predict(FOPR_input)\n",
    "            elif ts <= 60:\n",
    "                FOPR = fopr_gas_model2.predict(FOPR_input)\n",
    "            elif ts <= 90:\n",
    "                FOPR = fopr_gas_model3.predict(FOPR_input)\n",
    "            else:\n",
    "                FOPR = fopr_gas_model4.predict(FOPR_input)\n",
    "        else:\n",
    "            if ts <= 12:\n",
    "                FOPR = fopr_wat_model1.predict(FOPR_input)\n",
    "            elif ts <= 30:\n",
    "                FOPR = fopr_wat_model1.predict(FOPR_input)\n",
    "            elif ts <= 60:\n",
    "                FOPR = fopr_wat_model2.predict(FOPR_input)\n",
    "            elif ts <= 90:\n",
    "                FOPR = fopr_wat_model3.predict(FOPR_input)\n",
    "            else:\n",
    "                FOPR = fopr_wat_model4.predict(FOPR_input)\n",
    "\n",
    "        # transfer value from array to one value\n",
    "        FOPR = FOPR[0,0]\n",
    "        result = np.array([[ts_norm, FOPR]])\n",
    "        proxy_result = np.append(proxy_result, result, axis = 0)\n",
    "        FOPR_before = FOPR\n",
    "\n",
    "    # Throwing dummy value in index 0\n",
    "    proxy_result = proxy_result[1:,:]\n",
    "\n",
    "    # Plotting the result\n",
    "    FOPT_time = (proxy_result[:,1]*(1558.028809-0)+0)*30\n",
    "    FOPT = np.sum(FOPT_time)\n",
    "    \n",
    "    return FOPT\n",
    "\n",
    "def co2proxy1 (halfcycle,qg,qw):\n",
    "    #Normalization\n",
    "    halfcycle_norm = (halfcycle-3)/(12-3)\n",
    "    qg_norm = (qg-1)/(2-1)\n",
    "    qw_norm = (qw-3000)/(9000-3000)\n",
    "\n",
    "    # Defining temporary storage and variables\n",
    "    ts = 1\n",
    "    proxy_result = np.empty(shape=(1,2))\n",
    "    CO2_before = 0.003634399\n",
    "\n",
    "    # Looping through 122 timesteps\n",
    "    for ts in range (1, 123):\n",
    "        ts_norm = (ts-1)/(122-1)\n",
    "        CO2_input = np.array([[halfcycle_norm, qg_norm, qw_norm, ts_norm, CO2_before]])\n",
    "\n",
    "        # Determine whether to use gas or water proxy\n",
    "        temp = math.floor((ts-1)/(halfcycle_norm*9+3))\n",
    "        if (temp % 2) == 0:\n",
    "            if ts <= 12:\n",
    "                CO2 = co2_model0.predict(CO2_input)\n",
    "            elif ts <= 30:\n",
    "                CO2 = co2_gas_model1.predict(CO2_input)\n",
    "            elif ts <= 60:\n",
    "                CO2 = co2_gas_model2.predict(CO2_input)\n",
    "            elif ts <= 90:\n",
    "                CO2 = co2_gas_model3.predict(CO2_input)\n",
    "            else:\n",
    "                CO2 = co2_gas_model4.predict(CO2_input)\n",
    "        else:\n",
    "            if ts <= 12:\n",
    "                CO2 = co2_model0.predict(CO2_input)\n",
    "            elif ts <= 30:\n",
    "                CO2 = co2_wat_model1.predict(CO2_input)\n",
    "            elif ts <= 60:\n",
    "                CO2 = co2_wat_model2.predict(CO2_input)\n",
    "            elif ts <= 90:\n",
    "                CO2 = co2_wat_model3.predict(CO2_input)\n",
    "            else:\n",
    "                CO2 = co2_wat_model4.predict(CO2_input)\n",
    "\n",
    "        # transfer value from array to one value\n",
    "        CO2 = CO2[0,0]\n",
    "        result = np.array([[ts_norm, CO2]])\n",
    "        proxy_result = np.append(proxy_result, result, axis = 0)\n",
    "        CO2_before = CO2\n",
    "\n",
    "    # Throwing dummy value in index 0\n",
    "    proxy_result = proxy_result[1:,:]\n",
    "\n",
    "    # Denormalization\n",
    "    FCO2PT_time = (proxy_result[:,1]*(62301.45703+0)+0)*30\n",
    "    FCO2PT = np.sum(FCO2PT_time)\n",
    "    \n",
    "    return FCO2PT\n",
    "\n",
    "def CO2proxy(halfcycle,qg,qw):\n",
    "    time1 = math.floor(122 / (2 * halfcycle))\n",
    "    time2 = 122%(2 * halfcycle)\n",
    "    if math.floor(time2 / halfcycle)==0:\n",
    "        gas_time = time1 * halfcycle + time2\n",
    "    else:\n",
    "        gas_time = time1 * halfcycle + halfcycle\n",
    "    \n",
    "    ## units in Msm3\n",
    "    sequestrated_co2 = gas_time * qg * 30 - co2proxy1(halfcycle,qg,qw)/42221\n",
    "    return sequestrated_co2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "122%(2 * 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing optimization study using NSGA-II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================================\n",
      "n_gen |  n_eval |   cv (min)   |   cv (avg)   |  n_nds  |     eps      |  indicator  \n",
      "=====================================================================================\n",
      "    1 |      40 |  0.00000E+00 |  0.775000000 |       4 |            - |            -\n",
      "    2 |      50 |  0.00000E+00 |  0.575000000 |       4 |  0.00000E+00 |            f\n",
      "    3 |      60 |  0.00000E+00 |  0.375000000 |       7 |  0.103741255 |            f\n",
      "    4 |      70 |  0.00000E+00 |  0.250000000 |       7 |  0.00000E+00 |            f\n",
      "    5 |      80 |  0.00000E+00 |  0.175000000 |       8 |  0.011863487 |            f\n",
      "    6 |      90 |  0.00000E+00 |  0.050000000 |       8 |  0.00000E+00 |            f\n",
      "    7 |     100 |  0.00000E+00 |  0.00000E+00 |       9 |  0.014721141 |        ideal\n",
      "    8 |     110 |  0.00000E+00 |  0.00000E+00 |       9 |  0.00000E+00 |            f\n",
      "    9 |     120 |  0.00000E+00 |  0.00000E+00 |       7 |  0.098828154 |        ideal\n",
      "   10 |     130 |  0.00000E+00 |  0.00000E+00 |       6 |  0.061686722 |        ideal\n",
      "   11 |     140 |  0.00000E+00 |  0.00000E+00 |       6 |  0.00000E+00 |            f\n",
      "   12 |     150 |  0.00000E+00 |  0.00000E+00 |       6 |  0.00000E+00 |            f\n",
      "   13 |     160 |  0.00000E+00 |  0.00000E+00 |       7 |  0.041451800 |            f\n",
      "   14 |     170 |  0.00000E+00 |  0.00000E+00 |       8 |  0.337447219 |        ideal\n",
      "   15 |     180 |  0.00000E+00 |  0.00000E+00 |       5 |  0.028826576 |            f\n",
      "   16 |     190 |  0.00000E+00 |  0.00000E+00 |       5 |  0.042048187 |            f\n",
      "   17 |     200 |  0.00000E+00 |  0.00000E+00 |       6 |  0.034826550 |        ideal\n",
      "   18 |     210 |  0.00000E+00 |  0.00000E+00 |       7 |  0.036069396 |            f\n",
      "   19 |     220 |  0.00000E+00 |  0.00000E+00 |       7 |  0.00000E+00 |            f\n",
      "   20 |     230 |  0.00000E+00 |  0.00000E+00 |       7 |  0.016493615 |            f\n",
      "   21 |     240 |  0.00000E+00 |  0.00000E+00 |       7 |  0.078361344 |        ideal\n",
      "   22 |     250 |  0.00000E+00 |  0.00000E+00 |       7 |  0.00000E+00 |            f\n",
      "   23 |     260 |  0.00000E+00 |  0.00000E+00 |       7 |  0.00000E+00 |            f\n",
      "   24 |     270 |  0.00000E+00 |  0.00000E+00 |       6 |  0.017499701 |            f\n",
      "   25 |     280 |  0.00000E+00 |  0.00000E+00 |       7 |  0.008320980 |            f\n",
      "   26 |     290 |  0.00000E+00 |  0.00000E+00 |       7 |  0.00000E+00 |            f\n",
      "   27 |     300 |  0.00000E+00 |  0.00000E+00 |       7 |  0.00000E+00 |            f\n",
      "   28 |     310 |  0.00000E+00 |  0.00000E+00 |       8 |  0.005462415 |        ideal\n",
      "   29 |     320 |  0.00000E+00 |  0.00000E+00 |       8 |  0.00000E+00 |            f\n",
      "   30 |     330 |  0.00000E+00 |  0.00000E+00 |       9 |  0.024091700 |            f\n",
      "   31 |     340 |  0.00000E+00 |  0.00000E+00 |       9 |  0.004020398 |        ideal\n",
      "   32 |     350 |  0.00000E+00 |  0.00000E+00 |      10 |  0.012867946 |            f\n",
      "   33 |     360 |  0.00000E+00 |  0.00000E+00 |      10 |  0.00000E+00 |            f\n",
      "   34 |     370 |  0.00000E+00 |  0.00000E+00 |      10 |  0.00000E+00 |            f\n",
      "   35 |     380 |  0.00000E+00 |  0.00000E+00 |      11 |  0.075224790 |        ideal\n",
      "   36 |     390 |  0.00000E+00 |  0.00000E+00 |      12 |  0.002391500 |            f\n",
      "   37 |     400 |  0.00000E+00 |  0.00000E+00 |      12 |  0.00000E+00 |            f\n",
      "   38 |     410 |  0.00000E+00 |  0.00000E+00 |      13 |  0.002964895 |        ideal\n",
      "   39 |     420 |  0.00000E+00 |  0.00000E+00 |      13 |  0.00000E+00 |            f\n",
      "   40 |     430 |  0.00000E+00 |  0.00000E+00 |      12 |  0.045986302 |        ideal\n",
      "   41 |     440 |  0.00000E+00 |  0.00000E+00 |      12 |  0.00000E+00 |            f\n",
      "   42 |     450 |  0.00000E+00 |  0.00000E+00 |      13 |  0.040415500 |        ideal\n",
      "   43 |     460 |  0.00000E+00 |  0.00000E+00 |      14 |  0.005861276 |            f\n",
      "   44 |     470 |  0.00000E+00 |  0.00000E+00 |      15 |  0.016388859 |        ideal\n",
      "   45 |     480 |  0.00000E+00 |  0.00000E+00 |      15 |  0.00000E+00 |            f\n",
      "   46 |     490 |  0.00000E+00 |  0.00000E+00 |      15 |  0.00000E+00 |            f\n",
      "   47 |     500 |  0.00000E+00 |  0.00000E+00 |      15 |  0.00000E+00 |            f\n",
      "   48 |     510 |  0.00000E+00 |  0.00000E+00 |      16 |  0.013421042 |        ideal\n",
      "   49 |     520 |  0.00000E+00 |  0.00000E+00 |      16 |  0.00000E+00 |            f\n",
      "   50 |     530 |  0.00000E+00 |  0.00000E+00 |      16 |  0.00000E+00 |            f\n",
      "   51 |     540 |  0.00000E+00 |  0.00000E+00 |      16 |  0.007482875 |        nadir\n",
      "   52 |     550 |  0.00000E+00 |  0.00000E+00 |      17 |  0.000928929 |            f\n",
      "   53 |     560 |  0.00000E+00 |  0.00000E+00 |      18 |  0.000542252 |            f\n",
      "   54 |     570 |  0.00000E+00 |  0.00000E+00 |      18 |  0.00000E+00 |            f\n",
      "   55 |     580 |  0.00000E+00 |  0.00000E+00 |      18 |  0.00000E+00 |            f\n",
      "   56 |     590 |  0.00000E+00 |  0.00000E+00 |      19 |  0.005135555 |            f\n",
      "   57 |     600 |  0.00000E+00 |  0.00000E+00 |      20 |  0.001198460 |            f\n",
      "   58 |     610 |  0.00000E+00 |  0.00000E+00 |      21 |  0.000044722 |            f\n",
      "   59 |     620 |  0.00000E+00 |  0.00000E+00 |      21 |  0.005060055 |        nadir\n",
      "   60 |     630 |  0.00000E+00 |  0.00000E+00 |      22 |  0.008291963 |        ideal\n",
      "   61 |     640 |  0.00000E+00 |  0.00000E+00 |      22 |  0.00000E+00 |            f\n",
      "   62 |     650 |  0.00000E+00 |  0.00000E+00 |      22 |  0.009710601 |        nadir\n",
      "   63 |     660 |  0.00000E+00 |  0.00000E+00 |      22 |  0.00000E+00 |            f\n",
      "   64 |     670 |  0.00000E+00 |  0.00000E+00 |      22 |  0.00000E+00 |            f\n",
      "   65 |     680 |  0.00000E+00 |  0.00000E+00 |      22 |  0.000417508 |            f\n",
      "   66 |     690 |  0.00000E+00 |  0.00000E+00 |      22 |  0.00000E+00 |            f\n",
      "   67 |     700 |  0.00000E+00 |  0.00000E+00 |      24 |  0.000262367 |            f\n",
      "   68 |     710 |  0.00000E+00 |  0.00000E+00 |      24 |  0.00000E+00 |            f\n",
      "   69 |     720 |  0.00000E+00 |  0.00000E+00 |      25 |  0.001365818 |            f\n",
      "   70 |     730 |  0.00000E+00 |  0.00000E+00 |      25 |  0.00000E+00 |            f\n",
      "   71 |     740 |  0.00000E+00 |  0.00000E+00 |      25 |  0.00000E+00 |            f\n",
      "   72 |     750 |  0.00000E+00 |  0.00000E+00 |      25 |  0.00000E+00 |            f\n",
      "   73 |     760 |  0.00000E+00 |  0.00000E+00 |      25 |  0.000952296 |            f\n",
      "   74 |     770 |  0.00000E+00 |  0.00000E+00 |      25 |  0.00000E+00 |            f\n",
      "   75 |     780 |  0.00000E+00 |  0.00000E+00 |      26 |  0.002313649 |            f\n",
      "   76 |     790 |  0.00000E+00 |  0.00000E+00 |      27 |  0.000221386 |            f\n",
      "   77 |     800 |  0.00000E+00 |  0.00000E+00 |      27 |  0.00000E+00 |            f\n",
      "   78 |     810 |  0.00000E+00 |  0.00000E+00 |      28 |  0.000359923 |            f\n",
      "   79 |     820 |  0.00000E+00 |  0.00000E+00 |      28 |  0.00000E+00 |            f\n",
      "   80 |     830 |  0.00000E+00 |  0.00000E+00 |      28 |  0.00000E+00 |            f\n",
      "   81 |     840 |  0.00000E+00 |  0.00000E+00 |      28 |  0.00000E+00 |            f\n",
      "   82 |     850 |  0.00000E+00 |  0.00000E+00 |      28 |  0.00000E+00 |            f\n",
      "   83 |     860 |  0.00000E+00 |  0.00000E+00 |      28 |  0.00000E+00 |            f\n",
      "   84 |     870 |  0.00000E+00 |  0.00000E+00 |      28 |  0.00000E+00 |            f\n",
      "   85 |     880 |  0.00000E+00 |  0.00000E+00 |      28 |  0.00000E+00 |            f\n",
      "   86 |     890 |  0.00000E+00 |  0.00000E+00 |      29 |  0.000368507 |            f\n",
      "   87 |     900 |  0.00000E+00 |  0.00000E+00 |      28 |  0.007318045 |        ideal\n",
      "   88 |     910 |  0.00000E+00 |  0.00000E+00 |      28 |  0.000072223 |            f\n",
      "   89 |     920 |  0.00000E+00 |  0.00000E+00 |      28 |  0.00000E+00 |            f\n",
      "   90 |     930 |  0.00000E+00 |  0.00000E+00 |      28 |  0.001348782 |            f\n",
      "   91 |     940 |  0.00000E+00 |  0.00000E+00 |      28 |  0.001417486 |            f\n",
      "   92 |     950 |  0.00000E+00 |  0.00000E+00 |      28 |  0.00000E+00 |            f\n",
      "   93 |     960 |  0.00000E+00 |  0.00000E+00 |      29 |  0.000225514 |            f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   94 |     970 |  0.00000E+00 |  0.00000E+00 |      30 |  0.001507099 |            f\n",
      "   95 |     980 |  0.00000E+00 |  0.00000E+00 |      30 |  0.00000E+00 |            f\n",
      "   96 |     990 |  0.00000E+00 |  0.00000E+00 |      30 |  0.00000E+00 |            f\n",
      "   97 |    1000 |  0.00000E+00 |  0.00000E+00 |      31 |  0.000624380 |            f\n",
      "   98 |    1010 |  0.00000E+00 |  0.00000E+00 |      32 |  0.000118815 |            f\n",
      "   99 |    1020 |  0.00000E+00 |  0.00000E+00 |      32 |  0.00000E+00 |            f\n",
      "  100 |    1030 |  0.00000E+00 |  0.00000E+00 |      32 |  0.000144258 |            f\n"
     ]
    }
   ],
   "source": [
    "# Define problem\n",
    "import time\n",
    "import numpy as np\n",
    "start_time = time.time()\n",
    "\n",
    "from pymoo.model.problem import FunctionalProblem\n",
    "\n",
    "objs = [\n",
    "    lambda x : -oilproxy(x[0],x[1],x[2]),\n",
    "    lambda x : -CO2proxy(x[0],x[1],x[2])    \n",
    "]\n",
    "\n",
    "constr_ieq = [\n",
    "    lambda x : x[0]%3\n",
    "]\n",
    "\n",
    "functional_problem = FunctionalProblem(3,\n",
    "                                       objs,\n",
    "                                       constr_ieq=constr_ieq,\n",
    "                                       xl=np.array([3,1,3000]),\n",
    "                                       xu=np.array([12,2,9000]))\n",
    "\n",
    "# Defining the integer and real value\n",
    "mask = [\"int\", \"real\", \"real\"]\n",
    "\n",
    "from pymoo.factory import get_sampling, get_crossover, get_mutation\n",
    "from pymoo.operators.mixed_variable_operator import MixedVariableSampling, MixedVariableMutation, MixedVariableCrossover\n",
    "\n",
    "sampling = MixedVariableSampling(mask, {\n",
    "    \"real\": get_sampling(\"real_random\"),\n",
    "    \"int\": get_sampling(\"int_random\")\n",
    "})\n",
    "\n",
    "crossover = MixedVariableCrossover(mask, {\n",
    "    \"real\": get_crossover(\"real_sbx\", prob=1.0, eta=3.0),\n",
    "    \"int\": get_crossover(\"int_sbx\", prob=1.0, eta=3.0)\n",
    "})\n",
    "\n",
    "mutation = MixedVariableMutation(mask, {\n",
    "    \"real\": get_mutation(\"real_pm\", eta=3.0),\n",
    "    \"int\": get_mutation(\"int_pm\", eta=3.0)\n",
    "})\n",
    "\n",
    "# test_problem = MyProblem()\n",
    "problem = functional_problem\n",
    "\n",
    "# Optimization Algorithm\n",
    "from pymoo.algorithms.nsga2 import NSGA2\n",
    "\n",
    "algorithm = NSGA2(\n",
    "    pop_size=40,\n",
    "    n_offsprings=10,\n",
    "    sampling=sampling,\n",
    "    crossover=crossover,\n",
    "    mutation=mutation,\n",
    "    eliminate_duplicates=True\n",
    ")\n",
    "\n",
    "# Define termination criterion\n",
    "from pymoo.factory import get_termination\n",
    "\n",
    "termination = get_termination(\"n_gen\", 100)\n",
    "\n",
    "# Perform Optimization study\n",
    "from pymoo.optimize import minimize\n",
    "\n",
    "res = minimize(problem,\n",
    "               algorithm,\n",
    "               termination,\n",
    "               seed=1,\n",
    "               save_history=True,\n",
    "               verbose=True)\n",
    "end_time = time.time()\n",
    "total_time = end_time-start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing the pareto optimum results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymoo.visualization.scatter.Scatter at 0x2617ee543d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pymoo.visualization.scatter import Scatter\n",
    "plot = Scatter()\n",
    "plot.add(res.F, color=\"red\")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 1.9936597786866121, 3824.8482248774253],\n",
       "       [9, 1.950332476029982, 6453.818741047197],\n",
       "       [6, 1.9936597786866121, 3980.64632107857],\n",
       "       [6, 1.994485573907254, 4428.354928446686],\n",
       "       [9, 1.989223707966187, 7616.036315424465],\n",
       "       [9, 1.995660829671841, 3202.345139515285],\n",
       "       [9, 1.9939028897429376, 3106.641700678267],\n",
       "       [6, 1.9994958074175062, 3489.145018291998],\n",
       "       [6, 1.98753090269023, 8918.335058112782],\n",
       "       [9, 1.9847503965525517, 3164.789411923234],\n",
       "       [6, 1.9829117986200144, 8902.882377703685],\n",
       "       [6, 1.9988205933897203, 4932.807038456842],\n",
       "       [6, 1.98246873606607, 8902.882377703685],\n",
       "       [6, 1.98753090269023, 8998.925552368692],\n",
       "       [6, 1.9979324950573174, 3801.697840584365],\n",
       "       [6, 1.9937570232601487, 3964.6772814086567],\n",
       "       [6, 1.988791498953224, 5034.868185208238],\n",
       "       [9, 1.9979324950573174, 3245.418994191581],\n",
       "       [9, 1.9648407376188652, 7136.063024921358],\n",
       "       [6, 1.9946141514062137, 3849.554306351742],\n",
       "       [6, 1.9949429174874866, 4050.57648213197],\n",
       "       [6, 1.9968426060993063, 4407.551365262348],\n",
       "       [3, 1.999967051619615, 8993.736851759484],\n",
       "       [6, 1.9994190918463506, 8968.955325470697],\n",
       "       [9, 1.9995411133989383, 3045.8481742413624],\n",
       "       [9, 1.991271999961342, 6735.324834713549],\n",
       "       [9, 1.999471863930808, 7258.679882864386],\n",
       "       [9, 1.9995343885557362, 3219.284199188971],\n",
       "       [6, 1.9931685732967113, 4646.310279841833],\n",
       "       [3, 1.9994190918463506, 8833.955986116674],\n",
       "       [6, 1.9994158430780224, 8937.74909532355],\n",
       "       [6, 1.9998191421964688, 3766.358793536205]], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.02523240e+06, -1.55452236e+03],\n",
       "       [-2.16304969e+06, -1.44970657e+03],\n",
       "       [-2.03877800e+06, -1.54431224e+03],\n",
       "       [-2.07335286e+06, -1.48333005e+03],\n",
       "       [-2.22625638e+06, -1.40739018e+03],\n",
       "       [-1.92557335e+06, -1.57734140e+03],\n",
       "       [-1.91833274e+06, -1.58511094e+03],\n",
       "       [-1.99183081e+06, -1.56396627e+03],\n",
       "       [-2.35262265e+06, -1.30518436e+03],\n",
       "       [-1.91873061e+06, -1.57798789e+03],\n",
       "       [-2.34999534e+06, -1.30736413e+03],\n",
       "       [-2.10165389e+06, -1.46263192e+03],\n",
       "       [-2.34982169e+06, -1.30760517e+03],\n",
       "       [-2.35667142e+06, -1.30428279e+03],\n",
       "       [-2.02419811e+06, -1.55724029e+03],\n",
       "       [-2.03743138e+06, -1.54570198e+03],\n",
       "       [-2.10358916e+06, -1.45300258e+03],\n",
       "       [-1.93054897e+06, -1.57410900e+03],\n",
       "       [-2.19910983e+06, -1.42681500e+03],\n",
       "       [-2.02773086e+06, -1.55399411e+03],\n",
       "       [-2.04530107e+06, -1.53762857e+03],\n",
       "       [-2.07310007e+06, -1.48585651e+03],\n",
       "       [-2.34661340e+06, -1.39296713e+03],\n",
       "       [-2.35991330e+06, -1.30039818e+03],\n",
       "       [-1.91721641e+06, -1.58921437e+03],\n",
       "       [-2.19004067e+06, -1.44824357e+03],\n",
       "       [-2.21648909e+06, -1.42512850e+03],\n",
       "       [-1.92834039e+06, -1.57678564e+03],\n",
       "       [-2.08442699e+06, -1.47245255e+03],\n",
       "       [-2.33809424e+06, -1.39356769e+03],\n",
       "       [-2.35834969e+06, -1.30080466e+03],\n",
       "       [-2.02090030e+06, -1.56016404e+03]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
